<html>

<head>

<title>Stats: Stein's paradox (January 27, 2000)</title>

</head>

<body><!--start-->

<p><strong>Stein's paradox (created 2000-01-27).</strong></p>

<p>This page is moving to a <a href="http://new.pmean.com/what-is-stein-paradox/">new website</a>.</p>

 <p><em>Dear Professor Mean, What is &quot;Stein's Paradox&quot;?</em></p>
  <blockquote>
       <p>Stein's paradox is rather technical and I'm not sure I can do it justice in this web page. 
       It is named for a statistician, Charles Stein, who discovered the paradox in the 1950's, 
       although the importance of this finding was fully understood until several decades later.</p>
       <p>We statisticians have known for a long time that the optimal estimate we could get from a 
       set of data is the mean. The definition of &quot;optimal&quot; is rather technical and I'm not sure I 
       could define it properly here. What Stein showed was that <strong>in a multivariate setting, 
       you can do better than the &quot;optimal&quot; mean if you were willing to live with some amount of 
       bias</strong>. This is the paradox: a procedure that is optimal in a univariate setting is 
       sub-optimal in a multivariate setting. It's also paradoxical because deliberately introducing 
       bias can sometimes improve your estimates.</p>
       <p>Consider a multi-center trial where we want to estimate the effect of a treatment for each 
       center. We could use the mean for all the patients at a given center to estimate that 
       center's effectiveness. Some centers will have a higher effectiveness than the overall rate 
       and some will have lower effectiveness.</p>
       <p>This is clearly better than ignoring the center effect and claiming that the effectiveness 
       of each center was exactly equal to the overall effectiveness rate. But it turns out that
       <strong>a weighted average between the individual center's mean and the overall mean is a 
       better estimate of that center's effectiveness, if you choose the weights carefully</strong>.</p>
       <p>In other words, the optimal estimate of an individual center's effectiveness is not the 
       average of that center's data alone, and it is not the overall average, but somewhere between 
       those two values.</p>
       <p><strong>Selecting an intermediate value is sometimes called shrinkage</strong>. Those 
       centers with above average estimates of effectiveness will have those estimates lowered 
       somewhat towards the overall mean and those centers with below average estimates will have 
       those estimates raised toward the overall mean. We &quot;shrink&quot; the individual center's estimates 
       partway towards the overall mean.</p>
       <p><strong>Shrinkage introduces some bias, but (if you shrink properly) the gain in precision 
       more than offsets the bias</strong>. The overall mean is a more stable estimate than the 
       individual means are, so incorporating the overall mean to some extent will provide greater 
       stability to the individual center estimates.</p>
       <p>A random effects model in meta-analysis uses shrinkage in a similar way. Each study 
       provides its own individual estimate, and we combine those studies to get an overall 
       estimate. <strong>The random effects meta-analysis tempers (nudges downward) the results from 
       the overly optimistic studies. It also nudges the overly pessimistic studies a bit higher</strong>.</p>
       <p>The amount of nudging depends on the size of each individual study (the smaller the study, 
       the more it is nudged) and how close the individual estimates are to the overall estimate 
       (the greater the homogeneity, the more each study is nudged).</p>
       <p>My explanation here is simplistic, partly because I don't understand all the technical 
       details myself. If you are really interested in more details, look for references that 
       discuss techniques like &quot;Empirical Bayes estimation&quot; and &quot;random effects models&quot;. You might 
       also want to try to understand the concept of &quot;regression toward the mean&quot; as it relates 
       closely to Stein's paradox.</p>
  </blockquote>
  
</body>

</html>
