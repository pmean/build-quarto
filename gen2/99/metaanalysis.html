<html>

<head>

<title>Stats: Guidelines for meta-analysis models (March 18, 2005)</title>

</head>

<body><!--start-->

<p><strong>Meta-analysis (March 18, 2005)</strong></p>
  
<p>This page is moving to a <a href="http://new.pmean.com/steps-in-meta-analysis/">new website</a>.</p>  
  
  <p>Meta-analysis is the quantitative combination of results from multiple research studies. There 
 are three steps in a typical meta-analysis model.</p>
  <p>
    Extract individual estimates and standard errors from each study</p>
  <p>
    Combine these estimates using a fixed or random effects model</p>
  <p>
    Display the results graphically.</p>
  <p>This page uses resources originally developed on my weblog:
  <a href="file:///J:/weblog2004/Heterogeneity.asp">November 29, 
  2004</a>, <a href="file:///J:/weblog2005/ForestPlots.asp">
  January 12, 2005</a>, February 25, 2005, and March 11, 2005. I also have a web page about the 
  special problems associated with a <a href="diagnostic.html">meta-analysis for a 
  diagnostic test</a> and&nbsp; a non-technical introduction on the
  <a href="../12a/journal/meta-analysis.asp">practical interpretation of a meta-analysis</a>.</p>
  <p><b>Step 1. Extract individual estimates.</b></p>
  <p>When you look at the individual summaries in a meta-analysis, they will report the results 
       in a variety of ways. You need to extract these results in a common format, and the process 
       depends a lot on the type of outcome being reported.</p>
  <p>For a continuous outcome, a commonly reported statistic is the difference between the 
       treatment mean and the control mean divided by the standard deviation in the control group.</p>
  <p><img border="0" src="../01/images/metaanalysis01.gif"></p>
  <p>For this equation and all equations below, the subscript iT represents data from the 
       treatment group of the ith study and the subscript iC represents data from the control group 
       of the ith study.</p>
  <p>It seems a bit unusual to use the standard deviation just from the control group. The 
       rationale is that if you have two or more treatments in a study compared to control, the 
       denominator never changes when you use just the control group standard deviation.</p>
  <p>There are some variations on this formula that use a pooled variance estimate or that 
       adjust for biases due to small sample sizes.</p>
  <p>The standard error of the estimate is</p>
  <p><img border="0" src="../01/images/metaanalysis02.gif"></p>
  <p>For a binary outcome, such as mortality, you have several choices. You can compute the 
       risk difference</p>
  <p><img border="0" src="../01/images/metaanalysis03.gif"></p>
  <p>You can also compute the relative risk, but traditionally, this is transformed to the log 
       scale first.</p>
  <p><img border="0" src="../01/images/metaanalysis04.gif"></p>
  <p>You can also compute the odds ratio, and this is almost always transformed to the log 
       scale as well.</p>
  <p><img border="0" src="../01/images/metaanalysis05.gif"></p>
  <p>The standard error of the risk difference is</p>
  <p><img border="0" src="../01/images/metaanalysis06.gif"></p>
  <p>For the relative risk and the odds ratio, we need to analyze the data on the log scale. 
       The log relative risk has a standard error of </p>
  <p><img border="0" src="../01/images/metaanalysis07.gif"></p>
  <p>and the log odds ratio has a standard error of</p>
  <p><img border="0" src="../01/images/metaanalysis08.gif"></p>
  <p>There is no consensus on the best measure among the risk difference, relative risk, or 
       odds ratio. The risk difference has certain advantages in interpretability, but the log odds 
       ratio often has fewer problems with heterogeneity.</p>
  <p><b>Step 2. Compute a preliminary estimate of overall effect.</b></p>
  <p>Now that you have all the data together, the first thing you want to do is to combine it. 
       In a perfect world, you would think carefully about your studies and the particular 
       meta-analysis model that you want and whether it makes sense to compute any combined estimate 
       at all. Only after a lot of careful thought would you proceed.</p>
  <p>But let's be realistic. You and I are both impatient, so we want to see right away what is 
       going on. So go ahead and compute a simple estimate of combined effect. Don't get emotionally 
       attached to that estimate, because a better choice might be a more complex estimate or 
       possibly no estimate at all.</p>
  <p>The simplest combined estimate is a weighted average of the individual study results. The 
       weights are inversely proportional to the square of the standard error,</p>
  <p><img border="0" src="../01/images/metaanalysis20.gif"></p>
  <p>which gives greater weight to those studies with smaller standard errors. The weighted 
       average is</p>
  <p><img border="0" src="../01/images/metaanalysis21.gif"></p>
  <p>where <font size="4">r</font> is the number of studies in the meta-analysis. This is known as the fixed effects 
       estimate. It is a good starting point for further analysis, but after you have taken a 
       careful look at this estimate and the individual studies that go into producing this 
       estimate, you may decide to use a different estimate or dispense entirely with estimating an 
       overall effect.</p>
  <p>The formulas for confidence limits for this estimate are simple enough, but I won't 
       present them here.</p>
  <p>Example: A meta-analysis of inhaled steroid use in chronic obstructive pulmonary disease:</p>
  <ul>
    <li><b>Effects of inhaled corticosteroids on sputum cell counts in stable chronic obstructive 
      pulmonary disease: a systematic review and a meta-analysis.</b> Gan WQ, Man SP, Sin DD. BMC 
      Pulm Med 2005: 5(1); 3.
      <a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&list_uids=15707484&dopt=Abstract">
      [Medline]</a> <a href="http://www.biomedcentral.com/1471-2466/5/3/abstract">[Abstract]</a>
      <a href="http://www.biomedcentral.com/1471-2466/5/3">[Full text]</a>
      <a href="http://www.biomedcentral.com/content/pdf/1471-2466-5-3.pdf">[PDF]</a></li>
  </ul>
  <p>showed standardized mean differences (smd) for the reduction in Total Cell counts and 
       confidence limits (lcl, ucl) in six studies in Table 3. I retyped that data in SPSS.</p>
  <p><img border="0" src="../01/images/metaanalysis31.gif"></p>
  <p>I computed the standard error by subtracting the lower confidence limit from the 
       standardized mean difference and then divided by 1.96. I also computed as the inverse of the 
       squared standard error to represent the weight for each study.</p>
  <p><img border="0" src="../01/images/metaanalysis32.gif"></p>
  <p>The sum of the weights is 35.37 and the sum of smd times the weights is -14.91. Divide the 
       second value by the first to get the overall estimate of -0.42. The fixed effects standard 
       error for the overall estimate is 0.17 and a 95% confidence interval is -0.09 to -0.75.</p>
  <p>Another example of a meta-analysis appears in</p>
  <ul>
    <li><b>Acetylcysteine for prevention of contrast-induced nephropathy after intravascular 
      angiography: a systematic review and meta-analysis.</b> Bagshaw SM, Ghali WA. BMC Med 2004: 
      2(1); 38.
      <a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&list_uids=15500690&dopt=Abstract">
      [Medline]</a> <a href="http://www.biomedcentral.com/1741-7015/2/38/abstract">[Abstract]</a>
      <a href="http://www.biomedcentral.com/1741-7015/2/38">[Full text]</a>
      <a href="http://www.biomedcentral.com/content/pdf/1741-7015-2-38.pdf">[PDF]</a></li>
  </ul>
  <p>I re-typed the table of odds ratios and 95% confidence intervals into Microsoft Excel.</p>
  <p><img border="0" src="../01/images/metaanalysis52.gif"></p>
  <p>To calculate a standard error, you first have to transform the odds ratio and the 
       confidence limits to the log scale. I used base 10 logarithms, here but any other type of 
       logarithm will also work.</p>
  <p><img border="0" src="../01/images/metaanalysis53.gif"></p>
  <p>To compute a standard error, take the log(ucl), subtract the log(or) and divide by 1.96. I 
       could have used the log(lcl) instead, but if you look at the original data, some of the lower 
       limits are 0.01 and 0.02. I was worried that there might be a lot of rounding error in those 
       values, since only one significant figure is displayed.</p>
  <p>Next, I computed weights and a weighted sum.</p>
  <p><img border="0" src="../01/images/metaanalysis54.gif"></p>
  <p>The overall estimate of the log odds ratio is -33.317 / 147.115 = -0.226. Take the inverse 
       of the sum of the weights and calculate a square root to get a standard error for this 
       combined estimate (0.082). A 95% confidence interval on the log scale is -0.387 to -0.065. 
       Transforming this back to the original scale of measurement gives you an overall odds ratio 
       of 0.59 and confidence limits of 0.41 to 0.86. </p>
  <p>Most commonly used statistical software does not include programs for meta-analysis. You 
       can download special user contributed libraries for meta-analysis for Stata and for R.</p>
  <p>Here is an example of an R program, plus the output using the meta library.</p>
  <p><code><font color="#FF0000">f0 &lt;- TotalCells.ma &lt;- &quot;X:/webdata/TotalCells.csv&quot;<br>
  Cells.dat &lt;- read.csv(f0)<br>
  attach(Cells.dat)<br>
  library(meta)<br>
  Cells.ma &lt;- metagen(TE=Cells.smd,seTE=Cells.se,studlab=study,sm=&quot;SMD&quot;)<br>
  print(Cells.ma)<br>
  plot(Cells.ma,comb.f=T)</font></code></p>
  <p><code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; SMD&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  95%-CI %W(fixed) %W(random)<br>
  Yildiz&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -0.6 [-1.5996;&nbsp; 0.3996]&nbsp;&nbsp;&nbsp;&nbsp; 
  10.98&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 10.98<br>
  Confalonieri -0.4 [-1.1056;&nbsp; 0.3056]&nbsp;&nbsp;&nbsp;&nbsp; 22.03&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  22.03<br>
  Mirici&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -1.0 [-1.7056; -0.2944]&nbsp;&nbsp;&nbsp;&nbsp; 22.03&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  22.03<br>
  Sugiura&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.2 [-0.7996;&nbsp; 1.1996]&nbsp;&nbsp;&nbsp;&nbsp; 
  10.98&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 10.98<br>
  Culpitt&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -0.3 [-1.1036;&nbsp; 0.5036]&nbsp;&nbsp;&nbsp;&nbsp; 16.99&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  16.99<br>
  Keatings&nbsp;&nbsp;&nbsp;&nbsp; -0.1 [-0.9036;&nbsp; 0.7036]&nbsp;&nbsp;&nbsp;&nbsp; 16.99&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  16.99<br>
  <br>
  Number of trials combined: 6 <br>
  <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  SMD&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 95%-CI&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  z p.value<br>
  Fixed effects model&nbsp; -0.4203 [-0.7515; -0.0891] -2.4874&nbsp; 0.0129<br>
  Random effects model -0.4203 [-0.7515; -0.0891] -2.4874&nbsp; 0.0129<br>
  <br>
  Quantifying heterogeneity:<br>
  tau^2 = 0; H = 1 [1; 1.96]; I^2 = 0% [0%; 74.1%]<br>
  <br>
  Test of heterogeneity:<br>
&nbsp; Q d.f. p.value<br>
  4.9&nbsp;&nbsp;&nbsp; 5&nbsp; 0.4287<br>
  <br>
  Method: Inverse variance method </code></p>
  <p>Notice that there is no difference between the random effects model and the fixed effects 
       model. That is because for this data set, there is no evidence of heterogeneity. The 
       Cochran's Q value is smaller than the degrees of freedom and the estimate of tau-squared is 
       zero.</p>
  <blockquote>
    <p>Here's what the analysis of the Acetylcysteine data would look like using R and the 
      meta library.</p>
  </blockquote>
  <p><code><font color="#FF0000">f0 &lt;- &quot;X:/webdata/Acetylcysteine1.csv&quot;<br>
  acetyl.dat &lt;- read.csv(f0)<br>
  attach(acetyl.dat)<br>
  log.or &lt;- log(or)<br>
  se &lt;- (log(ucl)-log.or)/1.96<br>
  acetyl.ma &lt;- metagen(TE=log.or,seTE=se,studlab=study,sm=&quot;OR&quot;)<br>
  print(acetyl.ma)<br>
  </font><br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; OR&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  95%-CI %W(fixed) %W(random)<br>
  Allaqaband&nbsp;&nbsp; 1.23 [0.3889; 3.8899]&nbsp;&nbsp;&nbsp;&nbsp; 10.44&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  9.18<br>
  Baker&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.20 [0.0400; 1.0000]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  5.34&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 6.41<br>
  Briguori&nbsp;&nbsp;&nbsp;&nbsp; 0.57 [0.1993; 1.6300]&nbsp;&nbsp;&nbsp;&nbsp; 12.54&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  9.93<br>
  Diaz-Sandova 0.11 [0.0224; 0.5400]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 5.47&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  6.50<br>
  Durham&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.27 [0.4518; 3.5699]&nbsp;&nbsp;&nbsp;&nbsp; 
  12.96&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 10.06<br>
  Efrati&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.19 [0.0086; 4.2098]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  1.44&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.40<br>
  Fung&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.37 [0.4345; 4.3199]&nbsp;&nbsp;&nbsp;&nbsp; 
  10.50&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 9.20<br>
  Goldenberg&nbsp;&nbsp; 1.30 [0.2721; 6.2098]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 5.66&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  6.64<br>
  Kay&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.29 [0.0895; 0.9400]&nbsp;&nbsp;&nbsp;&nbsp; 
  10.01&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 9.00<br>
  Kefer&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.63 [0.1013; 3.9199]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  4.14&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 5.44<br>
  MacNeill&nbsp;&nbsp;&nbsp;&nbsp; 0.11 [0.0125; 0.9700]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.92&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  4.24<br>
  Oldemeyer&nbsp;&nbsp;&nbsp; 1.30 [0.2744; 6.1598]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 5.72&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  6.68<br>
  Shyu&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.11 [0.0247; 0.4900]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  6.20&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 7.01<br>
  Vallero&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.14 [0.2691; 4.8299]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  6.64&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 7.29<br>
  <br>
  Number of trials combined: 14 <br>
  <br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  OR&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 95%-CI&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  z p.value<br>
  Fixed effects model&nbsp; 0.5937 [0.4092; 0.8612] -2.7468&nbsp;&nbsp; 0.006<br>
  Random effects model 0.5428 [0.3231; 0.9121] -2.3076&nbsp;&nbsp; 0.021<br>
  <br>
  Quantifying heterogeneity:<br>
  tau^2 = 0.4187; H = 1.35 [1; 1.84]; I^2 = 44.9% [0%; 70.5%]<br>
  <br>
  Test of heterogeneity:<br>
  &nbsp;&nbsp; Q d.f. p.value<br>
  23.6&nbsp; 13&nbsp;&nbsp;&nbsp; 0.035<br>
  <br>
  Method: Inverse variance method</code></p>
  <p>One important thing to note is that R expects you to use natural logarithms (base e) 
       rather than base 10 logarithms. When I first did this, I used base 10 logarithms and all the 
       results were too small.</p>
  <p>A common way to display the individual study results and a combined estimate of effects is 
       a graph known as a forest plot. An example of a forest plot appears in </p>
  <ul>
    <li><b>Acetylcysteine for prevention of contrast-induced nephropathy after intravascular 
      angiography: a systematic review and meta-analysis.</b> Bagshaw SM, Ghali WA. BMC Med 2004: 
      2(1); 38.
      <a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&list_uids=15500690&dopt=Abstract">
      [Medline]</a> <a href="http://www.biomedcentral.com/1741-7015/2/38/abstract">[Abstract]</a>
      <a href="http://www.biomedcentral.com/1741-7015/2/38">[Full text]</a>
      <a href="http://www.biomedcentral.com/content/pdf/1741-7015-2-38.pdf">[PDF]</a></li>
  </ul>
  <p>and because this is an open-access article, I can reproduce the graph here.</p>
  <p><img border="0" src="../01/images/ForestPlot01.gif"></p>
  <p>Since BMC Medicine is published with an
    <a href="http://www.biomedcentral.com/info/about/license">open access license</a>, I can 
       freely reproduce this image, as long as I cite the source.</p>
  <p>I was always confused by the funny squares in a forest plot, so I looked for a 
       description. Here is what the User's Guide for RevMan (software created by the Cochrane 
       Collaboration) says about forest plots:</p>
  <blockquote>
    <p><i>The graph is a forest plot where the confidence interval (CI) for each study is 
      represented by a horizontal line and the point estimate is represented by a square. The 
      size of the square corresponds to the weight of the study in the meta-analysis. The 
      confidence interval for totals are represented by a diamond shape. The scale used on the 
      graph depends on the statistical method. Dichotomous data (except for risk differences) 
      are displayed on a logarithmic scale. Continuous data and risk differences are displayed 
      on a linear scale. Generic inverse variance data are displayed on either a logarithmic 
      scale or a linear scale depending on the settings in RevMan.</i> --
      <a href="http://www.cc-ims.net/download/revman/Documentation/User%20guide.pdf">
      http://www.cc-ims.net/download/revman/Documentation/User%20guide.pdf</a> (page 36).</p>
  </blockquote>
  <p>Here is an example of the Forest plot, as drawn by R and the meta library.</p>
  <p><code><font color="#FF0000">&gt; plot(TotalCells.ma,comb.f=T)</font></code></p>
  <p><img border="0" src="../01/images/metaanalysis41.gif"></p>
  <p>Another way to display the results of a meta-analysis looks at the cumulative effect over 
       time as additional studies accumulate. At the top of the graph, you display the confidence 
       interval for the estimate from the first study published. Directly below that you display the 
       confidence interval for the combined effect of the first and second studies. Below that is 
       the combined effect of the first, second, and third studies, and so forth. An example of this 
       cumulative display appears in</p>
  <ul>
    <li><b>Erythropoietin, uncertainty principle and cancer related anaemia.</b> Clark O, Adams JR, 
      Bennett CL, Djulbegovic B. BMC Cancer 2002: 2(1); 23.
      <a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&list_uids=12270068&dopt=Abstract">
      [Medline]</a> <a href="http://www.biomedcentral.com/1471-2407/2/23/abstract">[Abstract]</a>
      <a href="http://www.biomedcentral.com/1471-2407/2/23">[Full text]</a>
      <a href="http://www.biomedcentral.com/content/pdf/1471-2407-2-23.pdf">[PDF]</a></li>
  </ul>
  <p>shows cumulative meta-analysis, which is the cumulated effects over time of studies in the 
       use of erythropoietin (EPO) to treat cancer related anemia.</p>
  <p><img border="0" src="../01/images/CumulativeMetaanalysis.gif"></p>
  <p>Since BMC Cancer is published with an
    <a href="http://www.biomedcentral.com/info/about/license">open access license</a>, I can 
       freely reproduce this image, as long as I cite the source.</p>
  <p>The outcome variable, the odds ratio for whether a patient requires transfusion, showed a 
       significant benefit for EPO. It also shows that sufficient evidence had already accumulated 
       by 1995 to demonstrate this benefit. If such a meta-analysis had been performed back then, 
       there would have been no need to run the additional trials. These redundant trials are bad 
       because they wasted scarce research dollars on a topic where sufficient information had 
       already been accumulated to answer the research question. They are also bad because half of 
       the patients in these post-1995 trials received no treatment or placebo, even though there 
       was enough evidence at that time to show that this is an inferior option.</p>
  <p>Some have suggested that any protocol submitted to an Institutional Review Board (IRB) 
       should include a systematic overview or meta-analysis of the previous research
    <font color="#FF0000">(see Chalmers 1996)</font>, rather than just a simple literature 
       review, to prevent future IRBs from making the same mistake of those that approved the 
       post-1995 studies of EPO. In some situations, that is definitely overkill, but it is a 
       suggestion worth serious consideration in other circumstances.</p>
  <p><b>Step 3. Evaluate the studies for publication bias and heterogeneity.</b></p>
  <p>After you have an overall estimate, you should compute the amount of variability of each 
       study from the overall estimate. You do this by computing a Z-score for each study,</p>
  <p><img border="0" src="../01/images/metaanalysis22.gif"></p>
  <p>and then seeing how much all of these Z-scores differ from zero by squaring the Z-scores 
       and adding them up. This gives you a test statistic, Cochran's Q,</p>
  <p><img border="0" src="../01/images/metaanalysis23.gif"></p>
  <p>An unusually large value for Q implies substantial heterogeneity, because you have more 
       variation among the studies than you would expect just by looking at the individual standard 
       errors. If there is no heterogeneity, then Q should be approximately equal to r-1, which 
       implies that the squared Z-scores are, on average, just slightly less than 1.</p>
  <p>Many experts have rejected the use of quantitative measures such as Cochran's Q for 
       assessing heterogeneity and suggest instead that you examine the studies qualitatively and 
       provide a subjective assessment of the degree of heterogeneity among the research studies.</p>
  <p>Another alternative is I-squared (<a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&list_uids=12958120&dopt=Abstract">Higgins 
       2003</a>), a statistic that measures the proportion of inconsistency in individual studies 
       that cannot be explained by chance.</p>
  <p><img border="0" src="../01/images/metaanalysis24.gif"></p>
  <p>Negative values are not allowed for I-squared. If you compute a negative value, set 
       I-squared to zero instead.</p>
  <p>I-squared is bounded above by 100% and values close to 100% represent very high degrees of 
       heterogeneity.</p>
  <p>This measure is preferred to Cochran's Q. The problem with Cochran's Q, the authors claim, 
       is that it tends to have too little power with a collection of studies with small sample 
       sizes and too much power with a collection of studies with large sample sizes. Values of 
       I-squared equal to 25%, 50%, and 75% representing low, moderate, and high heterogeneity, 
       respectively.</p>
  <p>The random effects model is an alternative way to combine estimates that explicitly 
       accounts for heterogeneity. In the random effects model, each study statistic is assumed to 
       be composed of</p>
  <p><img border="0" src="../01/images/metaanalysis21a.gif"></p>
  <p>where the second component is normally distributed random effect</p>
  <p><img border="0" src="../01/images/metaanalysis22a.gif"></p>
  <p>that accounts for the heterogeneity from study to study. A frequent criticism of the 
       random effects meta-analysis is this assumption that the random effects follow a bell shaped 
       curve. There is some suggestion that perhaps heterogeneity manifests itself as a bimodal 
       distribution instead.</p>
  <p>You can use the Method of Moments and Cochran's Q statistic to estimate the between study 
       variation:</p>
  <p><img border="0" src="../01/images/metaanalysis23a.gif"></p>
  <p>Notice that the numerator is a measure of how much the Cochran's Q statistic exceeds its 
       degrees of freedom. If you get a negative estimate here, simply replace it with an estimate 
       of zero.</p>
  <p>With an estimate of between study variation, you can now compute the random effects 
       estimate as a weighted average, just like the fixed effects estimate, except the weights in 
       the random effects estimate are</p>
  <p><img border="0" src="../01/images/metaanalysis24a.gif"></p>
  <p>where w<sub>i</sub> are the weights used in the fixed effects model.</p>
  <p>These weights are going to be closer to uniform or equal weighting than the weights in a 
       fixed effects model. If you think about it long enough, this is actually quite intuitive. In 
       a model where the study heterogeniety is large, large enough to dominate the standard errors, 
       you effectively have a random sample of studies each of which is more or less identically 
       distributed:</p>
  <p><img border="0" src="../01/images/metaanalysis25.gif"></p>
  <p>In addition to producing weights that are closer to equal weighting, the confidence 
       intervals for a random effects meta-analysis are typically wider than a fixed effects 
       meta-analysis because the estimated study heterogeneity adds an additional source of 
       uncertainty to the confidence interval calculations.</p>
  <p>The funnel plot is a graphical exploration of the study results looking for evidence of 
       publication bias. An example of a funnel plot appears in</p>
  <ul>
    <li><b>Oral rehydration versus intravenous therapy for treating dehydration due to 
      gastroenteritis in children: a meta-analysis of randomised controlled trials.</b> Bellemare 
      S, Hartling L, Wiebe N, Russell K, Craig WR, McConnell D, Klassen TP. BMC Med 2004: 2(1); 
      11.
      <a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&list_uids=15086953&dopt=Abstract">
      [Medline]</a> <a href="http://www.biomedcentral.com/1471-2288/4/20/abstract">[Abstract]</a>
      <a href="http://www.biomedcentral.com/1471-2288/4/20">[Full text]</a>
      <a href="http://www.biomedcentral.com/content/pdf/1471-2288-4-20.pdf">[PDF]</a></li>
  </ul>
  <p><img border="0" src="../01/images/metaanalysis11.jpg"></p>
  <p>Another funnel plot with conical guidelines superimposed appears in</p>
  <ul>
    <li><b>Association of circulating Chlamydia pneumoniae DNA with cardiovascular disease: a 
      systematic review.</b> Smieja M, Mahony J, Petrich A, Boman J, Chernesky M. BMC Infect Dis 
      2002: 2(1); 21.
      <a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&list_uids=12359046&dopt=Abstract">
      [Medline]</a> <a href="http://www.biomedcentral.com/1471-2334/2/21/abstract">[Abstract]</a>
      <a href="http://www.biomedcentral.com/1471-2334/2/21">[Full text]</a>
      <a href="http://www.biomedcentral.com/content/pdf/1471-2334-2-21.pdf">[PDF]</a></li>
  </ul>
  <p><img border="0" src="../01/images/metaanalysis12.jpg"></p>
  <p>Interestingly enough, most of the meta-analyses published in Biomed Central had the 
       following statement (almost word for word)</p>
  <blockquote>
    <p><i>Publication bias was not assessed using funnel plots as these tests have been 
      shown to be unhelpful.</i></p>
  </blockquote>
  <p>These articles then cited the following two references</p>
  <ul>
    <li><b>Misleading funnel plot for detection of bias in meta-analysis.</b> Tang JL, Liu JL. J 
      Clin Epidemiol 2000: 53(5); 477-84.
      <a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&list_uids=10812319&dopt=Abstract">
      [Medline]</a></li>
    <li><b>Publication and related bias in meta-analysis: power of statistical tests and prevalence 
      in the literature.</b> Sterne JA, Gavaghan D, Egger M. J Clin Epidemiol 2000: 53(11); 
      1119-29.
      <a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&list_uids=11106885&dopt=Abstract">
      [Medline]</a></li>
  </ul>
  <p>I have not yet read these articles, but I would agree that the funnel plot is often 
       difficult to interpret. There are some numerical summary measures that try to quantify the 
       departure from symmetry in the funnel plot, but these measures may also have problems.</p>
  <p>The trim and fill method uses the funnel plot to try to estimate the missing unpublished 
       studies. In this approach, studies that are asymmetrically distributed (that have no matching 
       study on the opposite side of the funnel plot) are removed from the plot. Then the funnel 
       plot is filled in using symmetric pairs from the trimmed study. This produces a funnel plot 
       with extra imputed studies that make the plot symmetric. The trim and fill method is quite 
       controversial and should be considered an exploratory approach. If, for example, you use this 
       method and the overall estimate changes by a trivial amount, then you have indirect evidence 
       that publication bias did not seriously influence your outcome. </p>
  <p><b>Further reading</b></p>
 <ul>
    <li><b>Changes in clinical trials mandated by the advent of meta-analysis.</b> Chalmers TC, Lau 
      J. Stat Med 1996: 15(12); 1263-8; discussion 1269-72.
      <a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&list_uids=8817800&dopt=Abstract">
      [Medline]</a></li>
    <li><b>Asymmetric funnel plots and publication bias in meta-analyses of diagnostic accuracy.</b> 
      Song F, Khan KS, Dinnes J, Sutton AJ. Int J Epidemiol 2002: 31(1); 88-95.
      <a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&list_uids=11914301&dopt=Abstract">
      [Medline]</a> <a href="http://www.ije.oupjournals.org/cgi/content/abstract/31/1/88">
      [Abstract]</a> <a href="http://www.ije.oupjournals.org/cgi/content/abstract/31/1/88">[Full 
            text]</a> <a href="http://www.ije.oupjournals.org/cgi/reprint/31/1/88.pdf">[PDF]</a></li>
    <li><b>Bias in meta-analysis detected by a simple, graphical test.</b> Egger M, Davey Smith G, 
      Schneider M, Minder C. British Medical Journal 1997: 315(7109); 629-34.
      <a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&list_uids=9310563&dopt=Abstract">
      [Medline]</a> <a href="http://bmj.bmjjournals.com/cgi/content/abstract/315/7109/629">
      [Abstract]</a> <a href="http://bmj.bmjjournals.com/cgi/content/full/315/7109/629">[Full 
            text]</a></li>
    <li><b>Measuring inconsistency in meta-analyses.</b> J. P. Higgins, S. G. Thompson, J. J. Deeks, 
      D. G. Altman. Bmj 2003: 327(7414); 557-60.
      <a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&list_uids=12958120&dopt=Abstract">
      [Medline]</a> <a href="http://bmj.bmjjournals.com/cgi/content/full/327/7414/557">[Full text]</a>
      <a href="http://bmj.bmjjournals.com/cgi/reprint/327/7414/557.pdf">[PDF]</a></li>
  </ul>
  
</body>

</html>
