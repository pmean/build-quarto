<html>

<head>

<title>Stats: Meta-analysis for a diagnostic test (no date)</title>

</head>

<body><!--start-->

<p><strong>Meta-analysis for a diagnostic (no date)</strong></p>

<p>This page is moving to a <a href="http://new.pmean.com/meta-analysis-for-diagnostic-test/">new website</a>.</p>

  <p>There is no real consensus yet on how to best combine data from several studies of a diagnostic 
  test. I will outline a few approaches that seem to make sense. In addition to this page, I have a
  <a href="metaanalysis.html">general overview on meta-analysis</a> and a non-technical 
  introduction on the <a href="../12a/journal/meta-analysis.asp">practical interpretation of a 
 meta-analysis</a>.</p>
  <p><b>Direct analysis of sensitivity/specificity</b></p>
  <blockquote>
       <p>The simplest overall estimate of sensitivity (sens) or specificity (spec) is to just 
       combine all the studies in a pot and stir. Just count the number of true positives (tp), 
       false negatives (fn), true negatives (tn) and false positives (fp) in each study. The overall 
       sensitivity would have the sum of the individual true positive values in the numerator and 
       the sum of the individual true positive plus false negative values in the denominator.</p>
       <p><img border="0" src="../01/images/diagnostic01.gif"></p>
       <p>This is equivalent to a weighted average of the individual sensitivities where the weights 
       for each individual study is simply the individual true positive plus false negative values. 
       You would calculate an overall estimate of sp.</p>
       <p>The tricky part comes when you try to define a confidence interval for the overall 
       estimate. This confidence interval is effectively a combination of the standard errors that 
       you would assign to each individual study.</p>
       <p>A first attempt might be to define the standard error of an individual study using the 
       classic binomial formula. Writing the standard error in terms of true positive and false 
       negative values, you would get</p>
       <p><img border="0" src="../01/images/diagnostic02.gif"></p>
       <p>The problem with this formula for the standard error is that it gives less weight to 
       studies where sensitivity is close to 50% and greater weight to studies where sensitivity is 
       much smaller than 50% or much larger than 50%. Another problem occurs when one or more of the 
       sensitivities is 100%. The standard error using a binomial distribution equals zero for those 
       studies with 100% sensitivity, which seems at first like a good thing. But when one study has&nbsp; 
       standard error of zero, the meta-analysis model will try to give it an infinite weight, which 
       is not at all a good thing.</p>
       <p>One way to avoid some of these problems is to estimate the standard error, not using the 
       individual sensitivities, but the overall sensitivity.</p>
       <p><img border="0" src="../01/images/diagnostic03.gif"></p>
       <p>Since the numerator is now the same for every study, you no longer have the problem where 
       studies with sensitivities near 50% get much smaller weights than studies with sensitivities 
       much smaller or much larger than 50%. This approach also avoids the problem when a study has 
       100% sensitivity.</p>
       <p>It's interesting to note that, the overall estimate and the standard error for the overall 
       sensitivity using this particular meta-analysis model with a fixed effects estimate matches 
       perfectly with the traditional binomial confidence interval that you might apply. This is 
       easy enough to show because</p>
       <p><img border="0" src="../01/images/diagnostic04.gif"></p>
       <p>which implies that</p>
       <p><img border="0" src="../01/images/diagnostic05.gif"></p>
       <p>For a random effects model, the results are a little more complicated and they do not 
       exactly match the traditional binomial confidence interval formula.</p>
       <p><b>Example</b>: In an article describing systematic reviews of diagnostic and screening 
       tests, </p>
       <ul>
        <li>
        <b>Systematic reviews in health care: Systematic reviews of evaluations of diagnostic and 
        screening tests.</b> Deeks JJ. British Medical Journal 2001: 323(7305); 157-62.
        <a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&list_uids=11463691&dopt=Abstract">
        [Medline]</a> <a href="http://bmj.bmjjournals.com/cgi/content/full/323/7305/157">[Full text]</a>
        <a href="http://bmj.bmjjournals.com/cgi/reprint/323/7305/157.pdf">[PDF]</a></ul>
       <p>data from 20 studies of endovaginal ultrasonography for detecting endometrial cancer are 
       presented. I typed the data in as a comma separated file.</p>
  </blockquote>
  <p><code>study,tp,fn,tn,fp<br>
  Abu Hmeidan,81,5,186,273<br>
  Auslender,16,0,48,90<br>
  Botsis,8,0,14,98<br>
  Cacclatore,4,0,30,11<br>
  Chan,15,2,15,35<br>
  Dorum,12,3,34,51<br>
  Goldstein,1,0,16,11<br>
  Granberg,18,0,32,125<br>
  Hanggi,18,3,13,55<br>
  Karlsson (a),112,2,414,601<br>
  Karlsson (b),14,1,33,57<br>
  Klug,7,1,44,127<br>
  Malinova,57,0,26,35<br>
  Nasri (a),7,0,14,38<br>
  Nasri (b),6,0,24,59<br>
  Petrl,18,1,96,35<br>
  Taviani,2,0,18,21<br>
  Varner,1,1,4,9<br>
  Weigel,37,0,91,72<br>
  Wolman,4,0,18,32</code></p>
  <blockquote>
       <p>and here is the R code to read in an compute the meta-analysis models.</p>
  </blockquote>
  <p><font color="#FF0000"><code>library(meta)<br>
  f0 &lt;- &quot;X:/webdata/EndovaginalUltrasonography.csv&quot;<br>
  deeks.example.dat &lt;- read.csv(f0)<br>
  attach(deeks.example.dat)<br>
  sens &lt;- tp / (tp + fn)<br>
  sens.overall &lt;- sum(tp) / sum(tp + fn)<br>
  spec &lt;- tn / (tn + fp)<br>
  spec.overall &lt;- sum(tn) / sum(tn + fp)<br>
  <br>
  par(mar=c(5.1,4.1,0.1,0.1))<br>
  plot(1-spec,sens,xlim=0:1,ylim=0:1)<br>
  points(1-spec.overall,sens.overall,pch=&quot;+&quot;,cex=2)</code></font></p>
  <blockquote>
       <p>The last three lines create a graph of the data, which is shown below. The par() function 
       adjusts the margins of the graph to make more effective use of the available space on the 
       screen. The plot() function creates the axes and draws a circle at each individual sens, 
       1-spec pair. The points() command adds a big plus sign at the overall estimate.</p>
  </blockquote>
  <p><img border="0" src="../01/images/diagnostic10.gif"></p>
  <blockquote>
       <p>Plotting 1-spec on the x-axis, which seems odd, but it is intended to have the same 
       orientation as an ROC curve. In fact, this plot is often called an SROC (Summary Receiver 
       Operating Characteristic) plot. </p>
       <p>I experimented with trying to show the confidence limits for each study in the graph 
       itself, by drawing rectangles with the width representing confidence limits for 1-spec and 
       the height representing confidence limits for sens. Unfortunately, this graph was too 
       cluttered to be useful.</p>
       <p>The computations for the actual meta-analysis are shown below. The code is a bit cryptic 
       perhaps, but I am using &quot;te&quot; as an abbreviation for &quot;treatment effect&quot; and &quot;se&quot; as an 
       abbreviation for &quot;standard error.&quot; The metagen() function has similar notation. The only 
       thing that is a bit confusing perhaps is the sm= portion. The letters &quot;sm&quot; stand for &quot;summary 
       measure. This is a label that metagen uses to make the output look nicer.</p>
  </blockquote>
  <p><font color="#FF0000"><code>te1 &lt;- sens<br>
  se1 &lt;- sqrt(sens.overall * (1 - sens.overall) / (tp + fn))<br>
  deeks1.ma &lt;- metagen(TE=te1, seTE=se1, studlab=study, sm=&quot;Sensitivity&quot;)<br>
  te2 &lt;- spec<br>
  se2 &lt;- sqrt(spec.overall * (1 - spec.overall) / (tn + fp))<br>
  deeks2.ma &lt;- metagen(TE=te2, seTE=se2, studlab=study, sm=&quot;Specificity&quot;)</code></font></p>
  <blockquote>
       <p>and here is the output</p>
  </blockquote>
  <p><code><font color="#FF0000">&gt; deeks1.ma</font><br>
  <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Sensitivity&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  95%-CI %W(fixed) %W(random)<br>
  Abu Hmeidan&nbsp; 0.9419 [0.8997; 0.9840]&nbsp;&nbsp;&nbsp;&nbsp; 18.82&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  10.27<br>
  Auslender&nbsp;&nbsp;&nbsp; 1.0000 [0.9022; 1.0978]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3.50&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  5.62<br>
  Botsis&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.0000 [0.8617; 1.1383]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  1.75&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3.61<br>
  Cacclatore&nbsp;&nbsp; 1.0000 [0.8044; 1.1956]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.88&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  2.10<br>
  Chan&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.8824 [0.7875; 0.9772]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  3.72&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 5.81<br>
  Dorum&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.8000 [0.6990; 0.9010]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  3.28&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 5.42<br>
  Goldstein&nbsp;&nbsp;&nbsp; 1.0000 [0.6088; 1.3912]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.22&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  0.60<br>
  Granberg&nbsp;&nbsp;&nbsp;&nbsp; 1.0000 [0.9078; 1.0922]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3.94&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  5.99<br>
  Hanggi&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.8571 [0.7718; 0.9425]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  4.60&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 6.47<br>
  Karlsson (a) 0.9825 [0.9458; 1.0191]&nbsp;&nbsp;&nbsp;&nbsp; 24.95&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  10.77<br>
  Karlsson (b) 0.9333 [0.8323; 1.0344]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3.28&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  5.42<br>
  Klug&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.8750 [0.7367; 1.0133]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  1.75&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3.61<br>
  Malinova&nbsp;&nbsp;&nbsp;&nbsp; 1.0000 [0.9482; 1.0518]&nbsp;&nbsp;&nbsp;&nbsp; 12.47&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  9.37<br>
  Nasri (a)&nbsp;&nbsp;&nbsp; 1.0000 [0.8521; 1.1479]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.53&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  3.27<br>
  Nasri (b)&nbsp;&nbsp;&nbsp; 1.0000 [0.8403; 1.1597]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.31&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  2.91<br>
  Petrl&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.9474 [0.8576; 1.0371]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  4.16&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 6.16<br>
  Taviani&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.0000 [0.7233; 1.2767]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.44&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  1.15<br>
  Varner&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.5000 [0.2233; 0.7767]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  0.44&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.15<br>
  Weigel&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.0000 [0.9357; 1.0643]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  8.10&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 8.21<br>
  Wolman&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.0000 [0.8044; 1.1956]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  0.88&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.10<br>
  <br>
  Number of trials combined: 20 <br>
  <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  Sensitivity&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 95%-CI&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  z&nbsp; p.value<br>
  Fixed effects model&nbsp; 0.9584 [0.9401; 0.9767] 102.6404 &lt; 0.0001<br>
  Random effects model 0.9481 [0.9171; 0.9792]&nbsp; 59.8249 &lt; 0.0001<br>
  <br>
  Quantifying heterogeneity:<br>
  tau^2 = 0.002; H = 1.43 [1.1; 1.85]; I^2 = 51% [18.1%; 70.7%]<br>
  <br>
  Test of heterogeneity:<br>
&nbsp;&nbsp;&nbsp; Q d.f. p.value<br>
  38.75&nbsp; 19&nbsp;&nbsp; 0.0048<br>
  <br>
  Method: Inverse variance method <br>
  <font color="#FF0000"><br>
  &gt; deeks2.ma</font><br>
  <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Specificity&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  95%-CI %W(fixed) %W(random)<br>
  Abu Hmeidan&nbsp; 0.4052 [0.3606; 0.4498]&nbsp;&nbsp;&nbsp;&nbsp; 15.27&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  5.83<br>
  Auslender&nbsp;&nbsp;&nbsp; 0.3478 [0.2665; 0.4292]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 4.59&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  5.46<br>
  Botsis&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.1250 [0.0347; 0.2153]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  3.73&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 5.35<br>
  Cacclatore&nbsp;&nbsp; 0.7317 [0.5825; 0.8810]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.36&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  4.49<br>
  Chan&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.3000 [0.1648; 0.4352]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  1.66&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 4.71<br>
  Dorum&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.4000 [0.2963; 0.5037]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  2.83&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 5.17<br>
  Goldstein&nbsp;&nbsp;&nbsp; 0.5926 [0.4087; 0.7765]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.90&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  3.97<br>
  Granberg&nbsp;&nbsp;&nbsp;&nbsp; 0.2038 [0.1275; 0.2801]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 5.22&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  5.52<br>
  Hanggi&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.1912 [0.0753; 0.3071]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  2.26&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 4.99<br>
  Karlsson (a) 0.4079 [0.3779; 0.4379]&nbsp;&nbsp;&nbsp;&nbsp; 33.78&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  5.93<br>
  Karlsson (b) 0.3667 [0.2659; 0.4674]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3.00&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  5.21<br>
  Klug&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.2573 [0.1842; 0.3304]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  5.69&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 5.56<br>
  Malinova&nbsp;&nbsp;&nbsp;&nbsp; 0.4262 [0.3039; 0.5486]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.03&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  4.90<br>
  Nasri (a)&nbsp;&nbsp;&nbsp; 0.2692 [0.1367; 0.4018]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.73&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  4.75<br>
  Nasri (b)&nbsp;&nbsp;&nbsp; 0.2892 [0.1843; 0.3941]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.76&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  5.15<br>
  Petrl&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.7328 [0.6493; 0.8163]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  4.36&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 5.43<br>
  Taviani&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.4615 [0.3085; 0.6146]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.30&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  4.43<br>
  Varner&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.3077 [0.0426; 0.5728]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  0.43&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.91<br>
  Weigel&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.5583 [0.4834; 0.6331]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  5.42&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 5.54<br>
  Wolman&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.3600 [0.2248; 0.4952]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  1.66&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 4.71<br>
  <br>
  Number of trials combined: 20 <br>
  <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Specificity&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  95%-CI&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; z&nbsp; p.value<br>
  Fixed effects model&nbsp; 0.3894 [0.3719; 0.4068] 43.7721 &lt; 0.0001<br>
  Random effects model 0.3845 [0.3216; 0.4475] 11.9685 &lt; 0.0001<br>
  <br>
  Quantifying heterogeneity:<br>
  tau^2 = 0.0172; H = 3.26 [2.77; 3.85]; I^2 = 90.6% [86.9%; 93.2%]<br>
  <br>
  Test of heterogeneity:<br>
&nbsp;&nbsp;&nbsp;&nbsp; Q d.f.&nbsp; p.value<br>
  202.17&nbsp;&nbsp; 19 &lt; 0.0001<br>
  <br>
  Method: Inverse variance method </code></p>
  <blockquote>
       <p>Notice that there is substantial evidence of heterogeneity in both the sensitivity and 
       specificity values.</p>
  </blockquote>
  <p><b>Analysis of sensitivity/specificity on the log odds scale</b></p>
  <blockquote>
       <p>Another approach is to transform the sensitivity/specificity to the log odds scale before 
       entering the data into a meta-analysis model. The log odds transformation is a common 
       transformation for binomial data and serves as the heart of a logistic regression model. The 
       standard error for the log odds sensitivity has a nice simple approximation. To derive this, 
       you have to remember a simple formula about variances of a function. </p>
       <p><img border="0" src="../01/images/diagnostic11.gif"></p>
       <p>This formula relies on two things you forgot from your days of calculus, how to take a 
       derivative and how to apply a Taylor series expansion. </p>
       <p>The details are tedious, but not difficult. When you use this formula on the log odds 
       function, you get the following approximation.</p>
       <p><img border="0" src="../01/images/diagnostic13.gif"></p>
       <p>Compare this to the standard error for sensitivity shown above. The numerator for the 
       standard error has now moved in with its downstairs neighbor, leaving the upstairs empty. For 
       the log odds for sensitivity, this the opposite problem from the sensitivity. Studies with 
       sensitivity close to 50% have greater weight on the log odds scale than studies with 
       sensitivity larger than 50%.</p>
       <p>You can simplify this formula further. Note that the denominator of sens<sub>i</sub> can 
       cancel out the tp<sub>i</sub>+fn<sub>i</sub> term right next to it. With a bit more algebra, 
       you can get</p>
       <p><img border="0" src="../01/images/diagnostic14.gif"></p>
       <p>The log odds transformation also has some problems when the sensitivity is 100%. A simple 
       fix is to add an arbitrary constant (usually 0.5) to both the numerator and denominator. 
       Another approach would be to use the more complex formula listed above, but substitute the 
       overall sensitivity for the individual sensitivity.</p>
       <p>Example: Let's use the example in Deeks 2001 again. Here is the R code to compute log odds 
       and analyze the data in a meta-analysis model. Note that the pmax function replaces the zeros 
       in fn with 0.5.</p>
  </blockquote>
  <p><font color="#FF0000"><code><br>
  logit &lt;- function(p) {log(p)-log(1-p)}<br>
  fn.adj &lt;- pmax(fn,0.5)<br>
  sens &lt;- tp/(tp+fn.adj)<br>
  te3 &lt;- logit(sens)<br>
  se3 &lt;- sqrt(1/tp+1/fn.adj)<br>
  deeks3.ma &lt;- metagen(TE=te3,seTE=se3,studlab=study,sm=&quot;Log Odds Sens&quot;)<br>
  spec &lt;- tn/(tn+fp)<br>
  te4 &lt;- logit(spec)<br>
  se4 &lt;- sqrt(1/tn+1/fp)<br>
  deeks4.ma &lt;- metagen(TE=te4,seTE=se4,studlab=study,sm=&quot;Log Odds Spec&quot;)</code></font></p>
  <blockquote>
       <p>Here is the output. Using the summary function results in a briefer output because the 
       results of individual studies are not shown.</p>
  </blockquote>
  <p><code><font color="#FF0000">summary(deeks3.ma)<br>
  </font><br>
  Number of trials combined: 20 <br>
  <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Log Odds Sens&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  95%-CI&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; z&nbsp; p.value<br>
  Fixed effects model&nbsp; 2.4775 [2.0562; 2.8987] 11.5269 &lt; 0.0001<br>
  Random effects model 2.4761 [2.0318; 2.9204] 10.9228 &lt; 0.0001<br>
  <br>
  Quantifying heterogeneity:<br>
  tau^2 = 0.0551; H = 1.03 [1; 1.27]; I^2 = 5.4% [0%; 38.1%]<br>
  <br>
  Test of heterogeneity:<br>
&nbsp;&nbsp;&nbsp; Q d.f. p.value<br>
  20.07&nbsp;&nbsp; 19&nbsp; 0.3901<br>
  <br>
  Method: Inverse variance method <br>
  <br>
  <font color="#FF0000">summary(deeks4.ma)<br>
  </font><br>
  Number of trials combined: 20 <br>
  <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Log Odds Spec&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  95%-CI&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; z&nbsp; p.value<br>
  Fixed effects model&nbsp; -0.4277 [-0.5036; -0.3518] -11.0403 &lt; 0.0001<br>
  Random effects model -0.5033 [-0.7668; -0.2399] -3.7446&nbsp;&nbsp;&nbsp; 0.0002<br>
  <br>
  Quantifying heterogeneity:<br>
  tau^2 = 0.292; H = 3.07 [2.58; 3.64]; I^2 = 89.4% [85%; 92.5%]<br>
  <br>
  Test of heterogeneity:<br>
&nbsp;&nbsp;&nbsp;&nbsp; Q d.f.&nbsp; p.value<br>
  178.76&nbsp;&nbsp; 19 &lt; 0.0001<br>
  <br>
  Method: Inverse variance method </code></p>
  <blockquote>
       <p>You need to do a few additional calculations to get sensitivity transformed back to the 
       original measurement scale. You can define a function in R to do this calculation for you. I 
       call it the expit function, which is the inverse of the logit function.</p>
  </blockquote>
  <p><font color="#FF0000"><code>expit &lt;- function(log.odds) {exp(log.odds)/(1+exp(log.odds))}</code></font></p>
  <blockquote>
       <p>With this function, you can now take the estimates and confidence limits on the log odds 
       scale and transform them back to the original scale.</p>
  </blockquote>
  <p><code><font color="#FF0000">attach(deeks3.ma)<br>
  est.and.cl.fixed &lt;- TE.fixed+c(0,-1.96,1.96)*seTE.fixed<br>
  round(100*expit(est.and.cl.fixed),1)</font><br>
  <br>
  92.3 88.7 94.8<br>
  <br>
  <font color="#FF0000">est.and.cl.random &lt;- TE.random+c(0,-1.96,1.96)*seTE.random<br>
  round(100*expit(est.and.cl.random),1)</font><br>
  <br>
  92.2 88.4 94.9<br>
  <br>
  <font color="#FF0000">attach(deeks4.ma)<br>
  est.and.cl.fixed &lt;- TE.fixed+c(0,-1.96,1.96)*seTE.fixed<br>
  round(100*expit(est.and.cl.fixed),1)</font><br>
  <br>
  39.5 37.7 41.3<br>
  <br>
  <font color="#FF0000">est.and.cl.random &lt;- TE.random+c(0,-1.96,1.96)*seTE.random<br>
  round(100*expit(est.and.cl.random),1)</font><br>
  <br>
  37.7 31.7 44.0</code></p>
  <blockquote>
       <p>The estimated sensitivity and 95% confidence limits under the fixed effects model are 
       92.3% (88.7% to 94.8%). The estimates and limits change only slightly under than random 
       effects model. The estimated specificity and 95% confidence limits under the fixed effect 
       model are 39.5% (37.7% to 41.3%). Under the random effects model, the estimate is a bit lower 
       and the confidence limits are much wider.</p>
  </blockquote>
  <p><b>Analysis of the diagnostic odds ratio</b></p>
  <blockquote>
       <p>A third approach is to compute the diagnostic odds ratio, which compares the odds for 
       sensitivity to the odds for specificity.</p>
       <p><img border="0" src="../01/images/diagnostic07.gif"></p>
       <p>Notice how the denominator looks like we accidentally switched things. That was not a 
       mistake. The diagnostic odds ratio is effectively the odds of TPR (the true positive rate or 
       sens) divided by the odds of FPR (the false positive rate or 1-spec).</p>
       <p>The first advantage of this approach is that you can use well-known approaches for 
       combining multiple odds ratios. The other advantage is that is analyzes sensitivity and 
       specificity as a pair. Some studies may exhibit heterogeneity in the individual sensitivity 
       or specificity values because one researcher may have tried to maximize sensitivity at the 
       expense of specificity, another may have tried to maximize specificity at the expense of 
       sensitivity, and a third may have tried to balance the two. If there is heterogeneity, then 
       the overall estimates of sensitivity and specificity may be too low.</p>
       <p>Although there are no guarantees, the diagnostic odds ratio should exhibit less 
       heterogeneity. The problem with the diagnostic odds ratio is that no one has a very good feel 
       on what it actually represents. One way of thinking about the diagnostic odds ratio is to 
       swap a couple of terms in the fraction.</p>
       <p><img border="0" src="../01/images/diagnostic15.gif"></p>
       <p>So you might interpret the diagnostic odds ratio as the spread between the two likelihood 
       ratios. If, for example, the likelihood ratio for a positive test is 10 and is 0.5 for a 
       negative test, then there is a 20 fold change. Another way of interpreting this is that the 
       post-test odds would be 20 fold higher for a positive test than for a negative test.</p>
       <p>The book on meta-analysis by Sutton et al suggests that&nbsp; you model the heterogeneity 
       in the diagnostic odds ratio using the following regression model</p>
       <p><img border="0" src="../01/images/diagnostic16.gif"></p>
       <p>You might recognize D as the diagnostic odds ratio. The variable S is a bit harder to 
       visualize, but you can rewrite it as</p>
       <p><img border="0" src="../01/images/diagnostic17.gif"></p>
       <p>This represents the tendency of an individual study to skew the test more towards 
       sensitivity or more towards specificity.</p>
       <p>Here's an example of the problems that can happen when different studies skew more towards 
       sensitivity and others more towards specificity. Imagine a diagnostic test that takes on a 
       range of values. This test follows a bell shaped curve both in the diseased and the healthy 
       populations and the two bell curves are set two standard deviations apart. You could set a 
       cutpoint to maximize specificity, to maximize sensitivity, or something in between.</p>
       <p>This series of graphs shows what happens across a range of cutpoints.</p>
  </blockquote>
  <p><img border="0" src="../01/images/diagno5.gif"></p>
  <p><img border="0" src="../01/images/diagno6.gif"></p>
  <p><img border="0" src="../01/images/diagno7.gif"></p>
  <p><img border="0" src="../01/images/diagno8.gif"></p>
  <p><img border="0" src="../01/images/diagno9.gif"></p>
  <p><img border="0" src="../01/images/diagno10.gif"></p>
  <p><img border="0" src="../01/images/diagno11.gif"></p>
  <p><img border="0" src="../01/images/diagno12.gif"></p>
  <p><img border="0" src="../01/images/diagno13.gif"></p>
  <p><img border="0" src="../01/images/diagno14.gif"></p>
  <p><img border="0" src="../01/images/diagno15.gif"></p>
  <blockquote>
       <p>When you graph the data on an SROC plot, you get a nice distribution of values. Notice, 
       however, that the average of all these sensitivities and specificities is pushed further away 
       from the upper left hand corner than any of the individual sensitivity/specificity pairs.</p>
  </blockquote>
  <p><img border="0" src="../01/images/diagnostic18.gif"></p>
  <blockquote>
       <p>By fitting a model to the diagnostic odds ratio, and assessing heterogeneity in that odds 
       ratio, you hope to avoid this obvious underestimate of sensitivity and specificity.</p>
       <p>When you fit the regression model, you are hoping is that the slope term is zero. That 
       tells you that the estimated intercept is a valid estimate across the range of S values.</p>
       <p>It's unclear whether to use a weighted regression model or an unweighted regression model 
       for these data.</p>
  </blockquote>
  <p><font color="#FF0000"><code>fn.adj &lt;- pmax(fn,0.5)<br>
  tpr &lt;- tp/(tp+fn.adj)<br>
  fpr &lt;- fp/(tn+fp)<br>
  d &lt;- logit(tpr)-logit(fpr)<br>
  s &lt;- logit(tpr)+logit(fpr)<br>
  se.d &lt;- sqrt(1/tp+1/fn.adj+1/tn+1/fp)<br>
  w &lt;- 1/se.d^2<br>
  unweighted.regression &lt;- lm(d~s)<br>
  weighted.regression &lt;- lm(d~s,weights=w)<br>
  par(mar=c(5.1,4.1,0.6,0.6))<br>
  plot(s,d)<br>
  abline(unweighted.regression)<br>
  abline(weighted.regression,lty=2)</code></font></p>
  <blockquote>
       <p>For this data set, it appears that there is a non-zero slope, which makes interpretation 
       of the combined diagnostic odds ratio problematic.</p>
  </blockquote>
  <p><img border="0" src="../01/images/diagno16.gif"></p>
  <p><code><font color="#FF0000">deeks5.ma &lt;- metagen(TE=d,seTE=se.d,studlab=study,sm=&quot;Log 
  Diagnostic Odds Ratio&quot;)<br>
  summary(deeks5.ma)<br>
  <br>
  </font>Number of trials combined: 20 <br>
  <br>
  Log Diagnostic Odds&nbsp; Ratio&nbsp;&nbsp; 95%-CI&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  z&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; p.value<br>
  Fixed effects model&nbsp; 1.9772 [1.5400; 2.4145] 8.8633 &lt; 0.0001<br>
  Random effects model 1.9732 [1.3618; 2.5847] 6.3249 &lt; 0.0001<br>
  <br>
  Quantifying heterogeneity:<br>
  tau^2 = 0.6555; H = 1.27 [1; 1.67]; I^2 = 38.4% [0%; 64%]<br>
  <br>
  Test of heterogeneity:<br>
&nbsp;&nbsp;&nbsp; Q d.f. p.value<br>
  30.87&nbsp; 19&nbsp; 0.0418<br>
  <br>
  Method: Inverse variance method </code></p>
  <p><b>Additional reading</b></p>
  <ul>
   <li>
   <b>Reporting of measures of accuracy in systematic reviews of diagnostic literature.</b> Honest 
   H, Khan KS. BMC Health Serv Res 2002: 2(1); 4.
   <a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&list_uids=11884248&dopt=Abstract">
   [Medline]</a> <a href="http://www.biomedcentral.com/1472-6963/2/4/abstract">[Abstract]</a>
   <a href="http://www.biomedcentral.com/1472-6963/2/4">[Full text]</a>
   <a href="http://www.biomedcentral.com/content/pdf/1472-6963-2-4.pdf">[PDF]</a><li>
   <b>Conducting systematic reviews of diagnostic studies: didactic guidelines.</b> Deville WL, 
   Buntinx F, Bouter LM, Montori VM, De Vet HC, Van Der Windt DA, Bezemer P. BMC Med Res Methodol 
   2002: 2(1); 9.
   <a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&list_uids=12097142&dopt=Abstract">
   [Medline]</a> <a href="http://www.biomedcentral.com/1471-2288/2/9/abstract">[Abstract]</a>
   <a href="http://www.biomedcentral.com/1471-2288/2/9">[Full text]</a>
   <a href="http://www.biomedcentral.com/content/pdf/1471-2288-2-9.pdf">[PDF]</a><li>
   <b>Systematic reviews in health care: Systematic reviews of evaluations of diagnostic and 
   screening tests.</b> Deeks JJ. British Medical Journal 2001: 323(7305); 157-62.
   <a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&list_uids=11463691&dopt=Abstract">
   [Medline]</a> <a href="http://bmj.bmjjournals.com/cgi/content/full/323/7305/157">[Full text]</a>
   <a href="http://bmj.bmjjournals.com/cgi/reprint/323/7305/157.pdf">[PDF]</a>   
  </ul>
 
</body>

</html>
